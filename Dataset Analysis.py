# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cZx1E8i9SXvbFhFv0Mv2zmRG-D2QBwED
"""

import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns 
import warnings

"""**Purpose of the Study**

In this study relation between years of experince and salary from different industries in U.S. was examined. 

Salaries are given in U.S. dollars. Ex: 103234 = 103234$

**INTRO TO RESEARCH METHODS**

**1. Mean** : Commonly referred to as the average. When we are looking to calculate the mean, we add up a list of numbers and then divide that number by the items on the list.  It’s not recommended as a standalone statistical analysis method. This is because doing so can potentially ruin the complete efforts behind the calculation, seeing as it is also related to the mode (the value that occurs most often) and median (the middle) in some data sets.

**2.  Standard deviation** : Standard deviation is a method of statistical analysis that measures the spread of data around the mean. Standard deviation is mainly used when we need to determine the dispersion of data points (whether or not they’re clustered). On a similar note to the downside of using mean, the standard deviation can be misleading when used as the only method in your statistical analysis.

**3. Regression** :  Regression is the relationship between a dependent variable (the data you’re looking to measure) and an independent variable (the data used to predict the dependent variable). One disadvantage of using regression as part of statistical analysis is that regression isn’t very distinctive, meaning that although the outliers on a scatter plot (or regression analysis graph) are important, so are the reasons as to why they’re outliers.

**4. Hypothesis Testing** : In statistical analysis, hypothesis testing, also known as “T Testing”, is a key to testing the two sets of random variables within the data set. This method is all about testing if a certain argument or conclusion is true for the data set. It allows for comparing the data against various hypotheses and assumptions. It can also assist in forecasting how decisions made could affect the business. Hypothesis testing can sometimes be clouded and skewed by common errors, like the placebo effect. This occurs when statistical analysts conducting the test falsely expect a certain result and then see that result, no matter the circumstances.

**5. Sample Size Determination** : When it comes to analyzing data for statistical analysis, sometimes the dataset is simply too large, making it difficult to collect accurate data for each element of the dataset. When this is the case, most go the route of analyzing a sample size, or smaller size, of data, which is called sample size determination. To do this correctly, you’ll need to determine the right size of the sample to be accurate. If the sample size is too small, you won’t have valid results at the end of your analysis.
As you analyze a new and untested variable of data within this method, you’ll need to rely on certain assumptions. Doing so could result in a completely inaccurate assumption. If this error occurs during this statistical analysis method, it can negatively affect the rest of your data analysis. These errors are called sampling errors and are measured by a confidence interval. For instance, if you state that your results are at a 90% confidence level, it means if you were to perform the same analysis again and again, 90% of the time your results will be the same.
"""

import io
url = 'https://raw.githubusercontent.com/Hakanonay5/datasetofhkn/master/Salary.csv'
df = pd.read_csv(url)


df

"""**VISUALIZING DATA**"""

sns.jointplot(df["YearsExperience"], df["Salary"], data = df)

sns.lmplot(x='YearsExperience' , y = 'Salary', data = df)

df.Salary.hist(color='pink')
plt.title("Histogram-Plot", y=1.1015, fontsize = 20)
plt.xlabel("Salary", labelpad = 14)
plt.ylabel("Frequency", labelpad = 14)

sns.boxplot(data = df.Salary)

"""**CENTRAL TENDENCY**"""

mean1 = df['Salary'].mean()
sum1 = df['Salary'].sum()
count1 = df['Salary'].count()
median1 = df['Salary'].median() 


print ('Mean salary: ' + str(mean1))
print ('Sum of salaries: ' + str(sum1))
print ('Count of salaries: ' + str(count1))
print ('Median salary: ' + str(median1))

""" **VARIABILITY**"""

max1 = df['Salary'].max()
min1 = df['Salary'].min()
std1 = df['Salary'].std() 
var1 = df['Salary'].var() 

print ('Max salary: ' + str(max1))
print ('Min salary: ' + str(min1))
print ('Standart Deviation of salaries: ' + str(std1))
print ('Variance of salaries: ' + str(var1))

df.describe()

sorted(df.Salary)
#Q1 = df.quantile(0.25)
#Q3 = df.quantile(0.75)
Q1,Q3 = np.percentile(df.Salary, [25,75])
IQR = Q3 - Q1

print("Outlier Data = " + str(IQR))

lower = Q1 - (1.5 * IQR)
upper = Q3 + (1.5 * IQR)
print("Lower bound =" + str(lower))
print("Upper bound=" + str(upper))

"""**STANDARDIZING**"""

#Normal Disturbition
datacount = 35
np.random.seed(42)


df_Salary = pd.DataFrame(data={'Salary': np.random.normal(loc=66, scale=2.9, size=datacount)})
df_Salary

#Z-Score

df_Salary['z-score'] = (df_Salary['Salary'] - mean1) / std1
df_Salary

"""**`NORMAL DISTRIBUTION & SAMPLING
DISTRIBUTIONS**
"""

sns.distplot(df_Salary['Salary'], color = "Red", hist = False)
plt.xlabel("Salary", labelpad = 12)
plt.ylabel("Probability", labelpad =12)
plt.title("Distribution of Salaries", y = 1.015, fontsize = 22)

df_Salary['z-score'].hist(color = 'black')
plt.title("Standart Normal Distribution", y=1.015, fontsize = 20)
plt.xlabel("z-score", labelpad = 14)
plt.ylabel("frequency", labelpad = 14)

Example_Salary = 84578 #Example to examine, 84.578$ Salary with unknown Years of experience

def z_score(value,mean1,std1):
  return round((value - mean1)/ std1, 5) #Shortcut Function to calculate z-score of a data

z_score_Example_Salary = z_score(Example_Salary,mean1,std1)
print("Example_Salary has a z-score of {0} for her price relative to other salaries.".format(z_score_Example_Salary))

from scipy import stats
#Probability of this example salaries more than the others ;
Example_Salary_more_expensive = round(stats.norm.cdf(z_score_Example_Salary),5)
Example_Salary_more_expensive

1 - Example_Salary_more_expensive
#Probability of this example salary's less than the others

#Probability of a random Salary being between of 2 values
Sal1 = 58934
Sal2 = 98234
z_score_Sal1 = z_score(Sal1,mean1,std1)
z_score_Sal2 = z_score(Sal2,mean1,std1)

print(z_score_Sal2)
print(z_score_Sal1)

finalresult = z_score_Sal2 - z_score_Sal1
print("Z-score of a random salary picked between Sal2 and Sal1 is equal to {0} .".format(finalresult))